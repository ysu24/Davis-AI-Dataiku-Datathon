{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Predicting Existence of BTM Using Random Forest Classifier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Notebook automatically generated from your model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Model Random forest (BTM Prediction), trained on 2022-09-24 14:28:04."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Generated on 2022-09-24 18:51:07.378861"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "prediction\n",
        "This notebook will reproduce the steps for a BINARY_CLASSIFICATION on  BTM_data_prepared.\n",
        "The main objective is to predict the variable BTM (Y/N)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Warning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The goal of this notebook is to provide an easily readable and explainable code that reproduces the main steps\n",
        "of training the model. It is not complete: some of the preprocessing done by the DSS visual machine learning is not\n",
        "replicated in this notebook. This notebook will not give the same results and model performance as the DSS visual machine\n",
        "learning model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's start with importing the required libs :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys\n",
        "import dataiku\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import sklearn as sk\n",
        "import dataiku.core.pandasutils as pdu\n",
        "from dataiku.doctor.preprocessing import PCA\n",
        "from collections import defaultdict, Counter"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "And tune pandas display options:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "pd.set_option('display.width', 3000)\n",
        "pd.set_option('display.max_rows', 200)\n",
        "pd.set_option('display.max_columns', 200)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Importing base data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The first step is to get our machine learning dataset:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CPU times: user 22.5 ms, sys: 6.26 ms, total: 28.8 ms\n",
            "Wall time: 71.1 ms\n",
            "Base data has 932 rows and 23 columns\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "            <button style=\"display:none\" \n",
              "            class=\"btn btn-default ipython-export-btn\" \n",
              "            id=\"btn-df-046209c8-93bc-4d53-b573-e5f176636b55\" \n",
              "            onclick=\"_export_df('046209c8-93bc-4d53-b573-e5f176636b55')\">\n",
              "                Export dataframe\n",
              "            </button>\n",
              "            \n",
              "            <script>\n",
              "                \n",
              "                function _check_export_df_possible(dfid,yes_fn,no_fn) {\n",
              "                    console.log('Checking dataframe exportability...')\n",
              "                    if(!IPython || !IPython.notebook || !IPython.notebook.kernel || !IPython.notebook.kernel) {\n",
              "                        console.log('Export is not possible (IPython kernel is not available)')\n",
              "                        if(no_fn) {\n",
              "                            no_fn();\n",
              "                        }\n",
              "                    } else {\n",
              "                        var pythonCode = 'from dataiku.notebook.export import IPythonExporter;IPythonExporter._check_export_stdout(\"'+dfid+'\")';\n",
              "                        IPython.notebook.kernel.execute(pythonCode,{iopub: {output: function(resp) {\n",
              "                            console.info(\"Exportability response\", resp);\n",
              "                            var size = /^([0-9]+)x([0-9]+)$/.exec(resp.content.data || resp.content.text)\n",
              "                            if(!size) {\n",
              "                                console.log('Export is not possible (dataframe is not in-memory anymore)')\n",
              "                                if(no_fn) {\n",
              "                                    no_fn();\n",
              "                                }\n",
              "                            } else {\n",
              "                                console.log('Export is possible')\n",
              "                                if(yes_fn) {\n",
              "                                    yes_fn(1*size[1],1*size[2]);\n",
              "                                }\n",
              "                            }\n",
              "                        }}});\n",
              "                    }\n",
              "                }\n",
              "            \n",
              "                function _export_df(dfid) {\n",
              "                    \n",
              "                    var btn = $('#btn-df-'+dfid);\n",
              "                    var btns = $('.ipython-export-btn');\n",
              "                    \n",
              "                    _check_export_df_possible(dfid,function() {\n",
              "                        \n",
              "                        window.parent.openExportModalFromIPython('Pandas dataframe',function(data) {\n",
              "                            btns.prop('disabled',true);\n",
              "                            btn.text('Exporting...');\n",
              "                            var command = 'from dataiku.notebook.export import IPythonExporter;IPythonExporter._run_export(\"'+dfid+'\",\"'+data.exportId+'\")';\n",
              "                            var callback = {iopub:{output: function(resp) {\n",
              "                                console.info(\"CB resp:\", resp);\n",
              "                                _check_export_df_possible(dfid,function(rows, cols) {\n",
              "                                    $('#btn-df-'+dfid)\n",
              "                                        .css('display','inline-block')\n",
              "                                        .text('Export this dataframe ('+rows+' rows, '+cols+' cols)')\n",
              "                                        .prop('disabled',false);\n",
              "                                },function() {\n",
              "                                    $('#btn-df-'+dfid).css('display','none');\n",
              "                                });\n",
              "                            }}};\n",
              "                            IPython.notebook.kernel.execute(command,callback,{silent:false}); // yes, silent now defaults to true. figures.\n",
              "                        });\n",
              "                    \n",
              "                    }, function(){\n",
              "                            alert('Unable to export : the Dataframe object is not loaded in memory');\n",
              "                            btn.css('display','none');\n",
              "                    });\n",
              "                    \n",
              "                }\n",
              "                \n",
              "                (function(dfid) {\n",
              "                \n",
              "                    var retryCount = 10;\n",
              "                \n",
              "                    function is_valid_websock(s) {\n",
              "                        return s && s.readyState==1;\n",
              "                    }\n",
              "                \n",
              "                    function check_conn() {\n",
              "                        \n",
              "                        if(!IPython || !IPython.notebook) {\n",
              "                            // Don't even try to go further\n",
              "                            return;\n",
              "                        }\n",
              "                        \n",
              "                        // Check if IPython is ready\n",
              "                        console.info(\"Checking conn ...\")\n",
              "                        if(IPython.notebook.kernel\n",
              "                        && IPython.notebook.kernel\n",
              "                        && is_valid_websock(IPython.notebook.kernel.ws)\n",
              "                        ) {\n",
              "                            \n",
              "                            _check_export_df_possible(dfid,function(rows, cols) {\n",
              "                                $('#btn-df-'+dfid).css('display','inline-block');\n",
              "                                $('#btn-df-'+dfid).text('Export this dataframe ('+rows+' rows, '+cols+' cols)');\n",
              "                            });\n",
              "                            \n",
              "                        } else {\n",
              "                            console.info(\"Conditions are not ok\", IPython.notebook.kernel);\n",
              "                            \n",
              "                            // Retry later\n",
              "                            \n",
              "                            if(retryCount>0) {\n",
              "                                setTimeout(check_conn,500);\n",
              "                                retryCount--;\n",
              "                            }\n",
              "                            \n",
              "                        }\n",
              "                    };\n",
              "                    \n",
              "                    setTimeout(check_conn,100);\n",
              "                    \n",
              "                })(\"046209c8-93bc-4d53-b573-e5f176636b55\");\n",
              "                \n",
              "            </script>\n",
              "            \n",
              "        <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Tree ID</th>\n",
              "      <th>Longitude</th>\n",
              "      <th>Latitude</th>\n",
              "      <th>Common Name</th>\n",
              "      <th>Condition Class / Infestation Pattern</th>\n",
              "      <th>List of Trees on  residential property</th>\n",
              "      <th>BTM positive trees self reported  on residential property</th>\n",
              "      <th>Number of BTM positive Tree Species on property</th>\n",
              "      <th>Dbh 1. inches</th>\n",
              "      <th>Dbh 2</th>\n",
              "      <th>Dbh 3</th>\n",
              "      <th>Dbh 4</th>\n",
              "      <th>Dbh 5</th>\n",
              "      <th>Dbh 6</th>\n",
              "      <th>Number Observed BTM Nests</th>\n",
              "      <th>Entry Source</th>\n",
              "      <th>BTM (Y/N)</th>\n",
              "      <th>Interest in Help</th>\n",
              "      <th>Tree Type (Ornamental | Fruiting / Flowering | Bush)</th>\n",
              "      <th>Distance to Water (feet)</th>\n",
              "      <th>Proposed Treatment Type (Insert/Injection; Manual Removal; Organic Spray)</th>\n",
              "      <th>Treatm.  Priority (1: High, 2: Med, 3: Low)</th>\n",
              "      <th>Geopoint</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>130.0</td>\n",
              "      <td>-69.633445</td>\n",
              "      <td>44.551271</td>\n",
              "      <td>Crabapple</td>\n",
              "      <td>Good</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>75</td>\n",
              "      <td>Bartlett Invent Feb 2022</td>\n",
              "      <td>Y</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Fruiting/Flowering</td>\n",
              "      <td>&gt;250</td>\n",
              "      <td>Organic Spray</td>\n",
              "      <td>1</td>\n",
              "      <td>POINT(-69.633445106 44.551270843)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>101.0</td>\n",
              "      <td>-69.629734</td>\n",
              "      <td>44.549535</td>\n",
              "      <td>Crabapple</td>\n",
              "      <td>Fair</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "      <td>21</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>50</td>\n",
              "      <td>Bartlett Invent Feb 2022</td>\n",
              "      <td>Y</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Fruiting/Flowering</td>\n",
              "      <td>&gt;250</td>\n",
              "      <td>Organic Spray</td>\n",
              "      <td>1</td>\n",
              "      <td>POINT(-69.629734075 44.549535104)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>59.0</td>\n",
              "      <td>-69.627131</td>\n",
              "      <td>44.551959</td>\n",
              "      <td>Elm-American</td>\n",
              "      <td>Good</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>50</td>\n",
              "      <td>Bartlett Invent Feb 2022</td>\n",
              "      <td>Y</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Ornamental</td>\n",
              "      <td>&lt;25</td>\n",
              "      <td>Insert/Injection</td>\n",
              "      <td>1</td>\n",
              "      <td>POINT(-69.627130501 44.551959107)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>105.0</td>\n",
              "      <td>-69.629361</td>\n",
              "      <td>44.549576</td>\n",
              "      <td>Elm-American</td>\n",
              "      <td>Good</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "      <td>42</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>50</td>\n",
              "      <td>Bartlett Invent Feb 2022</td>\n",
              "      <td>Y</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Ornamental</td>\n",
              "      <td>&gt;250</td>\n",
              "      <td>Insert/Injection</td>\n",
              "      <td>1</td>\n",
              "      <td>POINT(-69.629360613 44.549576086)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>353.0</td>\n",
              "      <td>-69.662301</td>\n",
              "      <td>44.528730</td>\n",
              "      <td>Oak-Northern Red</td>\n",
              "      <td>Good</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "      <td>24</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>50</td>\n",
              "      <td>Bartlett Invent Feb 2022</td>\n",
              "      <td>Y</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Ornamental</td>\n",
              "      <td>&gt;250</td>\n",
              "      <td>Insert/Injection</td>\n",
              "      <td>1</td>\n",
              "      <td>POINT(-69.662300718 44.528730089)</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Tree ID  Longitude   Latitude       Common Name Condition Class / Infestation Pattern List of Trees on  residential property BTM positive trees self reported  on residential property  Number of BTM positive Tree Species on property  Dbh 1. inches  Dbh 2  Dbh 3  Dbh 4  Dbh 5  Dbh 6  Number Observed BTM Nests              Entry Source BTM (Y/N) Interest in Help Tree Type (Ornamental | Fruiting / Flowering | Bush) Distance to Water (feet) Proposed Treatment Type (Insert/Injection; Manual Removal; Organic Spray)  Treatm.  Priority (1: High, 2: Med, 3: Low)                           Geopoint\n",
              "0    130.0 -69.633445  44.551271         Crabapple                                  Good                                    NaN                                                NaN                                                       1             10      0      0      0      0      0                         75  Bartlett Invent Feb 2022         Y              NaN                                 Fruiting/Flowering                       >250                                      Organic Spray                                                                   1  POINT(-69.633445106 44.551270843)\n",
              "1    101.0 -69.629734  44.549535         Crabapple                                  Fair                                    NaN                                                NaN                                                       1             21      0      0      0      0      0                         50  Bartlett Invent Feb 2022         Y              NaN                                 Fruiting/Flowering                       >250                                      Organic Spray                                                                   1  POINT(-69.629734075 44.549535104)\n",
              "2     59.0 -69.627131  44.551959      Elm-American                                  Good                                    NaN                                                NaN                                                       1              4      0      0      0      0      0                         50  Bartlett Invent Feb 2022         Y              NaN                                         Ornamental                        <25                                   Insert/Injection                                                                   1  POINT(-69.627130501 44.551959107)\n",
              "3    105.0 -69.629361  44.549576      Elm-American                                  Good                                    NaN                                                NaN                                                       1             42      0      0      0      0      0                         50  Bartlett Invent Feb 2022         Y              NaN                                         Ornamental                       >250                                   Insert/Injection                                                                   1  POINT(-69.629360613 44.549576086)\n",
              "4    353.0 -69.662301  44.528730  Oak-Northern Red                                  Good                                    NaN                                                NaN                                                       1             24      0      0      0      0      0                         50  Bartlett Invent Feb 2022         Y              NaN                                         Ornamental                       >250                                   Insert/Injection                                                                   1  POINT(-69.662300718 44.528730089)"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# We apply the preparation that you defined. You should not modify this.\n",
        "preparation_steps = []\n",
        "preparation_output_schema = {'columns': [{'name': 'Tree ID', 'type': 'string'}, {'name': 'Longitude', 'type': 'double'}, {'name': 'Latitude', 'type': 'double'}, {'name': 'Common Name', 'type': 'string'}, {'name': 'Condition Class / Infestation Pattern', 'type': 'string'}, {'name': 'List of Trees on  residential property', 'type': 'string'}, {'name': 'BTM positive trees self reported  on residential property', 'type': 'string'}, {'name': 'Number of BTM positive Tree Species on property', 'type': 'bigint'}, {'name': 'Dbh 1. inches', 'type': 'bigint'}, {'name': 'Dbh 2', 'type': 'bigint'}, {'name': 'Dbh 3', 'type': 'bigint'}, {'name': 'Dbh 4', 'type': 'bigint'}, {'name': 'Dbh 5', 'type': 'bigint'}, {'name': 'Dbh 6', 'type': 'bigint'}, {'name': 'Number Observed BTM Nests', 'type': 'bigint'}, {'name': 'Entry Source', 'type': 'string'}, {'name': 'BTM (Y/N)', 'type': 'boolean'}, {'name': 'Interest in Help', 'type': 'string'}, {'name': 'Tree Type (Ornamental | Fruiting / Flowering | Bush)', 'type': 'string'}, {'name': 'Distance to Water (feet)', 'type': 'string'}, {'name': 'Proposed Treatment Type (Insert/Injection; Manual Removal; Organic Spray)', 'type': 'string'}, {'name': 'Treatm.  Priority (1: High, 2: Med, 3: Low)', 'type': 'bigint'}, {'name': 'Geopoint', 'type': 'string'}], 'userModified': False}\n",
        "\n",
        "ml_dataset_handle = dataiku.Dataset('BTM_data_prepared')\n",
        "ml_dataset_handle.set_preparation_steps(preparation_steps, preparation_output_schema)\n",
        "%time ml_dataset = ml_dataset_handle.get_dataframe(limit = 100000)\n",
        "\n",
        "print ('Base data has %i rows and %i columns' % (ml_dataset.shape[0], ml_dataset.shape[1]))\n",
        "# Five first records\",\n",
        "ml_dataset.head(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Initial data management"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The preprocessing aims at making the dataset compatible with modeling.\n",
        "At the end of this step, we will have a matrix of float numbers, with no missing values.\n",
        "We'll use the features and the preprocessing steps defined in Models.\n",
        "\n",
        "Let's only keep selected features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "ml_dataset = ml_dataset[['Dbh 1. inches', 'Common Name', 'Latitude', 'BTM (Y/N)', 'Longitude', 'Distance to Water (feet)', 'Condition Class / Infestation Pattern', 'Tree Type (Ornamental | Fruiting / Flowering | Bush)']]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's first coerce categorical columns into unicode, numerical features into floats."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "# astype('unicode') does not work as expected\n",
        "\n",
        "def coerce_to_unicode(x):\n",
        "    if sys.version_info < (3, 0):\n",
        "        if isinstance(x, str):\n",
        "            return unicode(x,'utf-8')\n",
        "        else:\n",
        "            return unicode(x)\n",
        "    else:\n",
        "        return str(x)\n",
        "\n",
        "\n",
        "categorical_features = ['Common Name', 'Distance to Water (feet)', 'Condition Class / Infestation Pattern', 'Tree Type (Ornamental | Fruiting / Flowering | Bush)']\n",
        "numerical_features = ['Dbh 1. inches', 'Latitude', 'Longitude']\n",
        "text_features = []\n",
        "from dataiku.doctor.utils import datetime_to_epoch\n",
        "for feature in categorical_features:\n",
        "    ml_dataset[feature] = ml_dataset[feature].apply(coerce_to_unicode)\n",
        "for feature in text_features:\n",
        "    ml_dataset[feature] = ml_dataset[feature].apply(coerce_to_unicode)\n",
        "for feature in numerical_features:\n",
        "    if ml_dataset[feature].dtype == np.dtype('M8[ns]') or (hasattr(ml_dataset[feature].dtype, 'base') and ml_dataset[feature].dtype.base == np.dtype('M8[ns]')):\n",
        "        ml_dataset[feature] = datetime_to_epoch(ml_dataset[feature])\n",
        "    else:\n",
        "        ml_dataset[feature] = ml_dataset[feature].astype('double')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We are now going to handle the target variable and store it in a new variable:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "target_map = {'Y': 0, 'N': 1}\n",
        "ml_dataset['__target__'] = ml_dataset['BTM (Y/N)'].map(str).map(target_map)\n",
        "del ml_dataset['BTM (Y/N)']\n",
        "\n",
        "\n",
        "# Remove rows for which the target is unknown.\n",
        "ml_dataset = ml_dataset[~ml_dataset['__target__'].isnull()]\n",
        "\n",
        "ml_dataset['__target__'] = ml_dataset['__target__'].astype(np.int64)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Cross-validation strategy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The dataset needs to be split into 2 new sets, one that will be used for training the model (train set)\n",
        "and another that will be used to test its generalization capability (test set)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This is a simple cross-validation strategy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train data has 745 rows and 8 columns\n",
            "Test data has 187 rows and 8 columns\n"
          ]
        }
      ],
      "source": [
        "train, test = pdu.split_train_valid(ml_dataset, prop=0.8)\n",
        "print ('Train data has %i rows and %i columns' % (train.shape[0], train.shape[1]))\n",
        "print ('Test data has %i rows and %i columns' % (test.shape[0], test.shape[1]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Features preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The first thing to do at the features level is to handle the missing values.\n",
        "Let's reuse the settings defined in the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Imputed missing values in feature Dbh 1. inches with value 7.201342281879195\n",
            "Imputed missing values in feature Latitude with value 44.55097243547111\n",
            "Imputed missing values in feature Longitude with value -69.64657900802943\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/dss/dataiku-dss-10.0.5/python36.packages/ipykernel_launcher.py:23: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
          ]
        }
      ],
      "source": [
        "drop_rows_when_missing = []\n",
        "impute_when_missing = [{'feature': 'Dbh 1. inches', 'impute_with': 'MEAN'}, {'feature': 'Latitude', 'impute_with': 'MEAN'}, {'feature': 'Longitude', 'impute_with': 'MEAN'}]\n",
        "\n",
        "# Features for which we drop rows with missing values\"\n",
        "for feature in drop_rows_when_missing:\n",
        "    train = train[train[feature].notnull()]\n",
        "    test = test[test[feature].notnull()]\n",
        "    print ('Dropped missing records in %s' % feature)\n",
        "\n",
        "# Features for which we impute missing values\"\n",
        "for feature in impute_when_missing:\n",
        "    if feature['impute_with'] == 'MEAN':\n",
        "        v = train[feature['feature']].mean()\n",
        "    elif feature['impute_with'] == 'MEDIAN':\n",
        "        v = train[feature['feature']].median()\n",
        "    elif feature['impute_with'] == 'CREATE_CATEGORY':\n",
        "        v = 'NULL_CATEGORY'\n",
        "    elif feature['impute_with'] == 'MODE':\n",
        "        v = train[feature['feature']].value_counts().index[0]\n",
        "    elif feature['impute_with'] == 'CONSTANT':\n",
        "        v = feature['value']\n",
        "    train[feature['feature']] = train[feature['feature']].fillna(v)\n",
        "    test[feature['feature']] = test[feature['feature']].fillna(v)\n",
        "    print ('Imputed missing values in feature %s with value %s' % (feature['feature'], coerce_to_unicode(v)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can now handle the categorical features (still using the settings defined in Models):"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's dummy-encode the following features.\n",
        "A binary column is created for each of the 100 most frequent values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/dss/dataiku-dss-10.0.5/python36.packages/ipykernel_launcher.py:22: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dummy-encoded feature Common Name\n",
            "Dummy-encoded feature Distance to Water (feet)\n",
            "Dummy-encoded feature Condition Class / Infestation Pattern\n",
            "Dummy-encoded feature Tree Type (Ornamental | Fruiting / Flowering | Bush)\n",
            "Dummy-encoded feature Common Name\n",
            "Dummy-encoded feature Distance to Water (feet)\n",
            "Dummy-encoded feature Condition Class / Infestation Pattern\n",
            "Dummy-encoded feature Tree Type (Ornamental | Fruiting / Flowering | Bush)\n"
          ]
        }
      ],
      "source": [
        "LIMIT_DUMMIES = 100\n",
        "\n",
        "categorical_to_dummy_encode = ['Common Name', 'Distance to Water (feet)', 'Condition Class / Infestation Pattern', 'Tree Type (Ornamental | Fruiting / Flowering | Bush)']\n",
        "\n",
        "# Only keep the top 100 values\n",
        "def select_dummy_values(train, features):\n",
        "    dummy_values = {}\n",
        "    for feature in categorical_to_dummy_encode:\n",
        "        values = [\n",
        "            value\n",
        "            for (value, _) in Counter(train[feature]).most_common(LIMIT_DUMMIES)\n",
        "        ]\n",
        "        dummy_values[feature] = values\n",
        "    return dummy_values\n",
        "\n",
        "DUMMY_VALUES = select_dummy_values(train, categorical_to_dummy_encode)\n",
        "\n",
        "def dummy_encode_dataframe(df):\n",
        "    for (feature, dummy_values) in DUMMY_VALUES.items():\n",
        "        for dummy_value in dummy_values:\n",
        "            dummy_name = u'%s_value_%s' % (feature, coerce_to_unicode(dummy_value))\n",
        "            df[dummy_name] = (df[feature] == dummy_value).astype(float)\n",
        "        del df[feature]\n",
        "        print ('Dummy-encoded feature %s' % feature)\n",
        "\n",
        "dummy_encode_dataframe(train)\n",
        "\n",
        "dummy_encode_dataframe(test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's rescale numerical features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Rescaled Dbh 1. inches\n",
            "Rescaled Latitude\n",
            "Rescaled Longitude\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/dss/dataiku-dss-10.0.5/python36.packages/ipykernel_launcher.py:18: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
          ]
        }
      ],
      "source": [
        "rescale_features = {'Dbh 1. inches': 'AVGSTD', 'Latitude': 'AVGSTD', 'Longitude': 'AVGSTD'}\n",
        "for (feature_name, rescale_method) in rescale_features.items():\n",
        "    if rescale_method == 'MINMAX':\n",
        "        _min = train[feature_name].min()\n",
        "        _max = train[feature_name].max()\n",
        "        scale = _max - _min\n",
        "        shift = _min\n",
        "    else:\n",
        "        shift = train[feature_name].mean()\n",
        "        scale = train[feature_name].std()\n",
        "    if scale == 0.:\n",
        "        del train[feature_name]\n",
        "        del test[feature_name]\n",
        "        print ('Feature %s was dropped because it has no variance' % feature_name)\n",
        "    else:\n",
        "        print ('Rescaled %s' % feature_name)\n",
        "        train[feature_name] = (train[feature_name] - shift).astype(np.float64) / scale\n",
        "        test[feature_name] = (test[feature_name] - shift).astype(np.float64) / scale"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Modeling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Before actually creating our model, we need to split the datasets into their features and labels parts:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_train = train.drop('__target__', axis=1)\n",
        "X_test = test.drop('__target__', axis=1)\n",
        "\n",
        "y_train = np.array(train['__target__'])\n",
        "y_test = np.array(test['__target__'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now we can finally create our model!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "clf = RandomForestClassifier(n_estimators=100,\n",
        "    random_state=1337,\n",
        "    max_depth=14,\n",
        "    min_samples_leaf=1,\n",
        "    verbose=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We set \"class_weight\" as the weighting strategy:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "clf.class_weight = \"balanced\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "... And train the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "building tree 1 of 100\n",
            "building tree 2 of 100\n",
            "building tree 3 of 100\n",
            "building tree 4 of 100\n",
            "building tree 5 of 100\n",
            "building tree 6 of 100\n",
            "building tree 7 of 100\n",
            "building tree 8 of 100\n",
            "building tree 9 of 100\n",
            "building tree 10 of 100\n",
            "building tree 11 of 100\n",
            "building tree 12 of 100\n",
            "building tree 13 of 100\n",
            "building tree 14 of 100\n",
            "building tree 15 of 100\n",
            "building tree 16 of 100\n",
            "building tree 17 of 100\n",
            "building tree 18 of 100\n",
            "building tree 19 of 100\n",
            "building tree 20 of 100\n",
            "building tree 21 of 100\n",
            "building tree 22 of 100\n",
            "building tree 23 of 100\n",
            "building tree 24 of 100\n",
            "building tree 25 of 100\n",
            "building tree 26 of 100\n",
            "building tree 27 of 100\n",
            "building tree 28 of 100\n",
            "building tree 29 of 100\n",
            "building tree 30 of 100\n",
            "building tree 31 of 100\n",
            "building tree 32 of 100\n",
            "building tree 33 of 100\n",
            "building tree 34 of 100\n",
            "building tree 35 of 100\n",
            "building tree 36 of 100\n",
            "building tree 37 of 100\n",
            "building tree 38 of 100\n",
            "building tree 39 of 100\n",
            "building tree 40 of 100\n",
            "building tree 41 of 100\n",
            "building tree 42 of 100\n",
            "building tree 43 of 100\n",
            "building tree 44 of 100\n",
            "building tree 45 of 100\n",
            "building tree 46 of 100\n",
            "building tree 47 of 100\n",
            "building tree 48 of 100\n",
            "building tree 49 of 100\n",
            "building tree 50 of 100\n",
            "building tree 51 of 100\n",
            "building tree 52 of 100\n",
            "building tree 53 of 100\n",
            "building tree 54 of 100\n",
            "building tree 55 of 100\n",
            "building tree 56 of 100\n",
            "building tree 57 of 100\n",
            "building tree 58 of 100\n",
            "building tree 59 of 100\n",
            "building tree 60 of 100\n",
            "building tree 61 of 100\n",
            "building tree 62 of 100\n",
            "building tree 63 of 100\n",
            "building tree 64 of 100\n",
            "building tree 65 of 100\n",
            "building tree 66 of 100\n",
            "building tree 67 of 100\n",
            "building tree 68 of 100\n",
            "building tree 69 of 100\n",
            "building tree 70 of 100\n",
            "building tree 71 of 100\n",
            "building tree 72 of 100\n",
            "building tree 73 of 100\n",
            "building tree 74 of 100\n",
            "building tree 75 of 100\n",
            "building tree 76 of 100\n",
            "building tree 77 of 100\n",
            "building tree 78 of 100\n",
            "building tree 79 of 100\n",
            "building tree 80 of 100\n",
            "building tree 81 of 100\n",
            "building tree 82 of 100\n",
            "building tree 83 of 100\n",
            "building tree 84 of 100\n",
            "building tree 85 of 100\n",
            "building tree 86 of 100\n",
            "building tree 87 of 100\n",
            "building tree 88 of 100\n",
            "building tree 89 of 100\n",
            "building tree 90 of 100\n",
            "building tree 91 of 100\n",
            "building tree 92 of 100\n",
            "building tree 93 of 100\n",
            "building tree 94 of 100\n",
            "building tree 95 of 100\n",
            "building tree 96 of 100\n",
            "building tree 97 of 100\n",
            "building tree 98 of 100\n",
            "building tree 99 of 100\n",
            "building tree 100 of 100\n",
            "CPU times: user 225 ms, sys: 19 ms, total: 244 ms\n",
            "Wall time: 230 ms\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.2s finished\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
              "            criterion='gini', max_depth=14, max_features='auto',\n",
              "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
              "            min_impurity_split=None, min_samples_leaf=1,\n",
              "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
              "            n_estimators=100, n_jobs=None, oob_score=False,\n",
              "            random_state=1337, verbose=2, warm_start=False)"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "%time clf.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Build up our result dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The model is now trained, we can apply it to our test set:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CPU times: user 26 ms, sys: 3.4 ms, total: 29.4 ms\n",
            "Wall time: 27.1 ms\n",
            "CPU times: user 23.1 ms, sys: 1.05 ms, total: 24.2 ms\n",
            "Wall time: 23.9 ms\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
          ]
        }
      ],
      "source": [
        "%time _predictions = clf.predict(X_test)\n",
        "%time _probas = clf.predict_proba(X_test)\n",
        "predictions = pd.Series(data=_predictions, index=X_test.index, name='predicted_value')\n",
        "cols = [\n",
        "    u'probability_of_value_%s' % label\n",
        "    for (_, label) in sorted([(int(target_map[label]), label) for label in target_map])\n",
        "]\n",
        "probabilities = pd.DataFrame(data=_probas, index=X_test.index, columns=cols)\n",
        "\n",
        "# Build scored dataset\n",
        "results_test = X_test.join(predictions, how='left')\n",
        "results_test = results_test.join(probabilities, how='left')\n",
        "results_test = results_test.join(test['__target__'], how='left')\n",
        "results_test = results_test.rename(columns= {'__target__': 'BTM (Y/N)'})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's have a look at feature importances"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fe2872845f8>"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "feature_importances_data = []\n",
        "features = X_train.columns\n",
        "for feature_name, feature_importance in zip(features, clf.feature_importances_):\n",
        "    feature_importances_data.append({\n",
        "        'feature': feature_name,\n",
        "        'importance': feature_importance\n",
        "    })\n",
        "\n",
        "# Plot the results\n",
        "pd.DataFrame(feature_importances_data)\\\n",
        "    .set_index('feature')\\\n",
        "    .sort_values(by='importance')[-10::]\\\n",
        "    .plot(title='Top 10 most important variables',\n",
        "          kind='barh',\n",
        "          figsize=(10, 6),\n",
        "          color='#348ABD',\n",
        "          alpha=0.6,\n",
        "          lw='1',\n",
        "          edgecolor='#348ABD',\n",
        "          grid=False,)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "You can measure the model's accuracy:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "AUC value: 0.9313797313797313\n"
          ]
        }
      ],
      "source": [
        "from dataiku.doctor.utils.metrics import mroc_auc_score\n",
        "y_test_ser = pd.Series(y_test)\n",
        " \n",
        "print ('AUC value:', mroc_auc_score(y_test_ser, _probas))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can also view the predictions directly.\n",
        "Since scikit-learn only predicts numericals, the labels have been mapped to 0,1,2 ...\n",
        "We need to 'reverse' the mapping to display the initial labels."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "9      Y\n",
              "11     Y\n",
              "17     Y\n",
              "19     Y\n",
              "21     Y\n",
              "24     Y\n",
              "27     Y\n",
              "32     Y\n",
              "35     Y\n",
              "36     Y\n",
              "38     Y\n",
              "47     Y\n",
              "57     Y\n",
              "60     Y\n",
              "64     Y\n",
              "65     Y\n",
              "72     Y\n",
              "74     Y\n",
              "78     Y\n",
              "80     Y\n",
              "84     Y\n",
              "85     Y\n",
              "88     Y\n",
              "93     N\n",
              "109    Y\n",
              "111    Y\n",
              "137    Y\n",
              "152    Y\n",
              "155    Y\n",
              "158    Y\n",
              "159    Y\n",
              "165    N\n",
              "167    Y\n",
              "170    Y\n",
              "171    Y\n",
              "182    Y\n",
              "189    Y\n",
              "190    N\n",
              "206    Y\n",
              "211    Y\n",
              "212    N\n",
              "215    N\n",
              "216    N\n",
              "217    N\n",
              "224    N\n",
              "225    N\n",
              "227    N\n",
              "228    N\n",
              "240    Y\n",
              "248    Y\n",
              "251    Y\n",
              "258    Y\n",
              "271    N\n",
              "276    N\n",
              "285    N\n",
              "286    N\n",
              "288    N\n",
              "291    N\n",
              "292    N\n",
              "293    N\n",
              "297    N\n",
              "299    N\n",
              "300    N\n",
              "301    N\n",
              "312    N\n",
              "331    N\n",
              "333    N\n",
              "340    N\n",
              "343    N\n",
              "344    N\n",
              "345    N\n",
              "351    N\n",
              "355    Y\n",
              "371    N\n",
              "372    N\n",
              "383    N\n",
              "385    N\n",
              "396    N\n",
              "398    N\n",
              "417    N\n",
              "436    N\n",
              "439    N\n",
              "442    N\n",
              "444    N\n",
              "447    N\n",
              "457    N\n",
              "471    N\n",
              "480    N\n",
              "500    N\n",
              "501    N\n",
              "507    N\n",
              "518    N\n",
              "525    N\n",
              "534    N\n",
              "541    N\n",
              "542    N\n",
              "557    N\n",
              "573    N\n",
              "575    N\n",
              "576    N\n",
              "577    N\n",
              "581    N\n",
              "588    N\n",
              "589    N\n",
              "596    Y\n",
              "606    Y\n",
              "607    Y\n",
              "608    Y\n",
              "610    Y\n",
              "611    Y\n",
              "614    Y\n",
              "615    Y\n",
              "620    Y\n",
              "626    Y\n",
              "636    Y\n",
              "641    Y\n",
              "644    Y\n",
              "652    Y\n",
              "656    Y\n",
              "658    Y\n",
              "671    Y\n",
              "673    Y\n",
              "674    Y\n",
              "675    Y\n",
              "676    Y\n",
              "679    Y\n",
              "681    Y\n",
              "682    Y\n",
              "684    Y\n",
              "688    Y\n",
              "692    Y\n",
              "696    Y\n",
              "698    Y\n",
              "701    Y\n",
              "707    Y\n",
              "708    Y\n",
              "709    Y\n",
              "714    Y\n",
              "715    Y\n",
              "717    Y\n",
              "722    Y\n",
              "727    Y\n",
              "729    Y\n",
              "736    Y\n",
              "740    Y\n",
              "741    Y\n",
              "742    Y\n",
              "745    Y\n",
              "754    Y\n",
              "762    N\n",
              "770    Y\n",
              "772    N\n",
              "773    Y\n",
              "776    Y\n",
              "779    N\n",
              "780    Y\n",
              "781    N\n",
              "782    N\n",
              "788    Y\n",
              "797    N\n",
              "800    N\n",
              "802    N\n",
              "805    N\n",
              "807    Y\n",
              "811    N\n",
              "817    N\n",
              "845    N\n",
              "852    N\n",
              "854    Y\n",
              "859    N\n",
              "867    N\n",
              "870    Y\n",
              "871    N\n",
              "875    N\n",
              "879    N\n",
              "882    N\n",
              "890    Y\n",
              "891    Y\n",
              "893    Y\n",
              "895    N\n",
              "902    Y\n",
              "910    Y\n",
              "914    Y\n",
              "924    Y\n",
              "925    Y\n",
              "929    Y\n",
              "930    Y\n",
              "Name: predicted_value, dtype: object"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "inv_map = { target_map[label] : label for label in target_map}\n",
        "predictions.map(inv_map)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "That's it. It's now up to you to tune your preprocessing, your algo, and your analysis !\n"
      ]
    }
  ],
  "metadata": {
    "hide_input": false,
    "kernelspec": {
      "display_name": "Python 3.10.7 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.7"
    },
    "modifiedBy": "user9",
    "name": "Predicting BTM (Y/N) in BTM_data_prepared",
    "vscode": {
      "interpreter": {
        "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}
